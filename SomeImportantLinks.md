http://cs231n.stanford.edu/
http://www.deeplearningbook.org/
http://neuralnetworksanddeeplearning.com/
https://www.udacity.com/course/deep-learning--ud730
https://www.deeplearning.ai/
https://www.analyticsvidhya.com/blog/2016/04/deep-learning-computer-vision-introduction-convolution-neural-networks/
https://github.com/kjw0612/awesome-deep-vision#books
https://pandas.pydata.org/pandas-docs/stable/visualization.html
https://www.linkedin.com/feed/update/urn:li:activity:6361254835588788224
https://pandas.pydata.org/pandas-docs/stable/missing_data.html
https://pandas.pydata.org/pandas-docs/stable/visualization.html
https://www.linkedin.com/feed/update/urn:li:activity:6358892005619306497

â€”-Some important links for public datasets:

	1. https://github.com/awesomedata/awesome-public-datasets
	2. https://www.kaggle.com/datasets
	3. https://www.reddit.com/r/datasets/

https://github.com/Shujian2015/FreeML - Data Science Resources 
https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html - Example of data augmentation in Keras
https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/ - A short study of different deep learning architectures
https://www.linkedin.com/feed/update/urn:li:activity:6369219131291631616 - A curated list of links to study basics of maths for data science
https://www.linkedin.com/feed/update/urn:li:activity:6369957933740097536 - Data science resources by Randy Lao
https://www.linkedin.com/feed/update/urn:li:activity:6370815151196770304 - List of free books for ML/DS

------------Some blog posts for CNN architecture -------------

	1. https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cf51669e1624
	2. https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cc5d0adf648e
	3. https://blog.waya.ai/deep-residual-learning-9610bb62c355
	4. https://towardsdatascience.com/neural-network-architectures-156e5bad51ba

https://medium.com/factory-mind/regex-tutorial-a-simple-cheatsheet-by-examples-649dc1c3f285  - Nice article for regex in python


**************** some blog posts for understanding of LSTM and GRU ********************
      1. http://colah.github.io/posts/2015-08-Understanding-LSTMs/
      2. http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/
      3. https://isaacchanghau.github.io/post/lstm-gru-formula/
      4. https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21
      5. https://stackoverflow.com/questions/44273249/in-keras-what-exactly-am-i-configuring-when-i-create-a-stateful-lstm-layer-wi
      6. https://stats.stackexchange.com/questions/241985/understanding-lstm-units-vs-cells

**************** understanding attention and transfromers ************
	1. http://jalammar.github.io/illustrated-transformer/
	2. https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/#.XIzc2-bhWb8
	3. http://mlexplained.com/2017/12/29/attention-is-all-you-need-explained/
	4. https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/
	5. http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/
	6. http://nlp.seas.harvard.edu/2018/04/03/attention.html
	7. https://distill.pub/2016/augmented-rnns/#attentional-interfaces



*************** An easy way to calculate model correlations **********************
	1. https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/50827

************* A guide of model ensembling *********************
	1. https://mlwave.com/kaggle-ensembling-guide/
	2. http://blog.kaggle.com/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice/
	3. https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52224
	4. https://www.kaggle.com/c/allstate-claims-severity/discussion/25743
	5. https://www.kaggle.com/hhstrand/oof-stacking-regime
	6. https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52644


**************  Quora Insincere Questions Classification  ************************
	1. https://www.kaggle.com/c/quora-insincere-questions-classification/kernels
	2. https://www.kaggle.com/sudalairajkumar/a-look-at-different-embeddings
	3. https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings
	4. https://www.kaggle.com/shujian/single-rnn-with-4-folds-clr
	5. https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/80495
	6. https://www.kaggle.com/wowfattie/3rd-place

************  F-1 score calculation in Keras/TF  *****************
	1. https://www.kaggle.com/guglielmocamporese/macro-f1-score-keras
	2. https://www.kaggle.com/teasherm/keras-metric-for-f-score-tf-only

************ intro to sequence to sequnce learning in keras *******************
	1. https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html

***********  Notes on Fastai ****************
	1. https://towardsdatascience.com/fast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889

*********** Details on Random forest algorithm  ****************
	1. https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76
	2. https://stats.stackexchange.com/questions/308885/a-simple-clear-explanation-of-the-gini-impurity

*********   Details on ELMO  ***************
	1. https://arxiv.org/pdf/1802.05365.pdf
	2. https://www.analyticsvidhya.com/blog/2019/03/learn-to-use-elmo-to-extract-features-from-text/

**********  Details on BERT  *************
	1. https://jalammar.github.io/illustrated-transformer/
	2. https://medium.com/dissecting-bert
	2. http://mlexplained.com/2019/01/07/paper-dissected-bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding-explained/
	3. https://github.com/google-research/bert
	4. https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html
	5. https://medium.com/@ranko.mosic/googles-bert-nlp-5b2bb1236d78
	6. https://www.kaggle.com/httpwwwfszyc/bert-in-keras-taming  -- fine-tuning bert model in keras
	7. https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/

*********** Snapshot ensembling  ************
	1. https://arxiv.org/pdf/1704.00109.pdf
	2. https://machinelearningmastery.com/snapshot-ensemble-deep-learning-neural-network/

*********  Visual information and KL divergence  ****************
	1. https://colah.github.io/posts/2015-09-Visual-Information/
	2. https://towardsdatascience.com/demystifying-cross-entropy-e80e3ad54a8
	3. https://towardsdatascience.com/demystifying-kl-divergence-7ebe4317ee68

********* GAN and adversarial training  *******************
	1. https://medium.com/@ml.at.berkeley/tricking-neural-networks-create-your-own-adversarial-examples-a61eb7620fd8
	2. https://christophm.github.io/interpretable-ml-book/adversarial.html
	3. https://www.youtube.com/watch?v=CIfsB_EYsVI&list=WL&index=26&t=0s

*********  Center Loss   **************
	1. https://medium.com/mlreview/experiments-with-a-new-loss-term-added-to-the-standard-cross-entropy-85b080c42446
	2. https://ydwen.github.io/papers/WenECCV16.pdf

************  Focal Loss  **********
	1. https://medium.com/@14prakash/the-intuition-behind-retinanet-eb636755607d

**********  Humpback whale identification challenge  ********************
	1. https://www.kaggle.com/c/humpback-whale-identification/discussion/82352#latest-496361
	2. https://medium.com/@ducha.aiki/thanks-radek-7th-place-solution-to-hwi-2019-competition-738624e4c885

********* Explanation of Adaboost, GBM, XGBoost and boosting in general *************
	1. http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/
	2. https://medium.com/@gabrieltseng/gradient-boosting-and-xgboost-c306c1bcfaf5
	3. https://www.datacamp.com/community/tutorials/xgboost-in-python
	4. https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/
	5. https://www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost/
	6. https://towardsdatascience.com/boosting-algorithm-gbm-97737c63daa3
	7. https://towardsdatascience.com/boosting-algorithm-adaboost-b6737a9ee60c
	8. https://towardsdatascience.com/boosting-algorithm-xgboost-4d9ec0207d
	9. https://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf
	9. https://medium.com/mlreview/gradient-boosting-from-scratch-1e317ae4587d
	10. https://datascience.stackexchange.com/questions/10997/need-help-understanding-xgboosts-approximate-split-points-proposal --weighted quantile sketch
	11. https://towardsdatascience.com/boosting-your-way-to-the-top-with-xgboost-556fbe6b96d3 -- Weighted quantile sketch

 ********** Meaning of learning rate (eta) in XGBoost  *********************
 	1. https://www.kaggle.com/c/santander-customer-satisfaction/discussion/20208
 	2. https://stats.stackexchange.com/questions/354484/why-does-xgboost-have-a-learning-rate
 	3. https://machinelearningmastery.com/tune-learning-rate-for-gradient-boosting-with-xgboost-in-python/
 
 ***************  Time distributed layer keras  ****************
 	1. https://machinelearningmastery.com/timedistributed-layer-for-long-short-term-memory-networks-in-python/
 	2. https://datascience.stackexchange.com/questions/10836/the-difference-between-dense-and-timedistributeddense-of-keras
 	3. https://stackoverflow.com/questions/44611006/timedistributeddense-vs-dense-in-keras-same-number-of-parameters/51342835

*************  Attention in keras  *****************
	1. https://towardsdatascience.com/light-on-math-ml-attention-with-keras-dc8dbc1fad39
	2. https://github.com/keras-team/keras/issues/4962

*************  Top algorithms for recommender systems ************************
	1. https://www.linkedin.com/feed/update/urn:li:activity:6531880236227923968

************* Regression Analysis  **************
	2. https://www.analyticsvidhya.com/blog/2016/07/deeper-regression-analysis-assumptions-plots-solutions/
	3. https://towardsdatascience.com/assumptions-of-linear-regression-algorithm-ed9ea32224e1
	4. https://datascienceplus.com/how-to-detect-heteroscedasticity-and-rectify-it/
	5. https://stattrek.com/regression/slope-test.aspx
	6. https://dss.princeton.edu/online_help/analysis/interpreting_regression.htm
	7. https://statisticsbyjim.com/regression/standard-error-regression-vs-r-squared/
	8. https://www.stat.cmu.edu/~hseltman/309/Book/chapter9.pdf
	9. https://www.quora.com/Why-is-logistic-regression-considered-a-linear-model
	10.https://stats.stackexchange.com/questions/93569/why-is-logistic-regression-a-linear-classifier

*************  Time series forecasting ***************
	1. https://www.machinelearningplus.com/time-series/arima-model-time-series-forecasting-python/
	2. https://machinelearningmastery.com/time-series-forecasting-methods-in-python-cheat-sheet/
	3. https://www.kaggle.com/kanncaa1/time-series-prediction-tutorial-with-eda/notebook
	4. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/
	5. https://www.analyticsvidhya.com/blog/2018/09/multivariate-time-series-guide-forecasting-modeling-python-codes/
	6. https://machinelearningmastery.com/decompose-time-series-data-trend-seasonality/
	7. https://machinelearningmastery.com/basic-feature-engineering-time-series-data-python/
	8. https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/

************  Faceting and multivariable plotting with Seaborn  *****************
	1. https://www.kaggle.com/residentmario/faceting-with-seaborn
	2. https://www.kaggle.com/residentmario/multivariate-plotting

********  getting started with pytorch  *************
	1. https://github.com/MorvanZhou/PyTorch-Tutorial
	2. https://github.com/hunkim/PyTorchZeroToAll
	3. https://towardsdatascience.com/getting-started-with-pytorch-part-1-understanding-how-automatic-differentiation-works-5008282073ec
	4. https://towardsdatascience.com/pytorch-tutorial-distilled-95ce8781a89c
	6. https://pytorch.org/tutorials/beginner/nn_tutorial.html
	7. https://pytorch.org/docs/stable/notes/autograd.html
	8. https://pytorch.org/tutorials/beginner/data_loading_tutorial.html
	10. https://medium.com/@tmckenzie.nz/using-the-fastai-data-block-api-b4818e72155b
	11. https://discuss.pytorch.org/t/detach-no-grad-and-requires-grad/16915/10


***********  Big Data   ********************
	1. https://towardsdatascience.com/a-brief-introduction-to-pyspark-ff4284701873
	2. https://confluence.atlassian.com/bitbucketserver/basic-git-commands-776639767.html
	3. https://www.edureka.co/blog/how-to-use-github/

************  Face recognition and one shot learning  ***************
	1. https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/

***********  Details on linear regression   ***********
	1. http://r-statistics.co/Assumptions-of-Linear-Regression.html
	2. https://www.analyticsvidhya.com/blog/2016/07/deeper-regression-analysis-assumptions-plots-solutions/
	3. https://towardsdatascience.com/assumptions-of-linear-regression-algorithm-ed9ea32224e1
	4. https://datascienceplus.com/how-to-detect-heteroscedasticity-and-rectify-it/
	5. https://statisticsbyjim.com/regression/multicollinearity-in-regression-analysis/
	6. https://roamanalytics.com/2016/11/17/translation-and-scaling-invariance-in-regression-models/

******* Details on SVD and eigendecomposition  *****************
	1. https://math.stackexchange.com/questions/320220/intuitively-what-is-the-difference-between-eigendecomposition-and-singular-valu

********* Probability and statistics   ***********
	1. https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1
	2. https://ayearofai.com/rohan-3-deriving-the-normal-equation-using-matrix-calculus-1a1b16f65dda
	3. https://www.analyticsvidhya.com/blog/2018/01/anova-analysis-of-variance/

********  Different optimization algorithms in DL ************
	1. https://stats.stackexchange.com/questions/278104/how-can-it-be-trapped-in-a-saddle-point
	2. http://www.offconvex.org/2016/03/22/saddlepoints/
	3. http://www.ashukumar27.io/exponentially-weighted-average/ 
	4. https://www.youtube.com/watch?v=lWzo8CajF5s - Bias correction in exponentially weighted average.
	5. https://towardsdatascience.com/learning-parameters-part-2-a190bef2d12
	6. cs231n.github.io/neural-networks-3/#sgd

*********  Anomaly and outlier detection   ****************
	1. https://towardsdatascience.com/how-to-use-machine-learning-for-anomaly-detection-and-condition-monitoring-6742f82900d7
	2. https://iwringer.wordpress.com/2015/11/17/anomaly-detection-concepts-and-techniques/
	3. https://medium.com/@mehulved1503/effective-outlier-detection-techniques-in-machine-learning-ef609b6ade72

******* Naive Bayes Classifier  ************
	1. https://www.machinelearningplus.com/predictive-modeling/how-naive-bayes-algorithm-works-with-example-and-full-code/

***** PCA, covariance and correlation  **************
	1. https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues
	2. https://stats.stackexchange.com/questions/32174/pca-objective-function-what-is-the-connection-between-maximizing-variance-and-m/136072#136072
	3. https://stats.stackexchange.com/questions/217995/what-is-an-intuitive-explanation-for-how-pca-turns-from-a-geometric-problem-wit
	4. https://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch18.pdf
	5. https://math.stackexchange.com/questions/114072/what-is-the-proof-that-covariance-matrices-are-always-semi-definite
	6. https://towardsdatascience.com/let-us-understand-the-correlation-matrix-and-covariance-matrix-

*********  Batch Norm   *************
	1. https://pytorch.org/docs/stable/nn.html#batchnorm1d
	2. https://stackoverflow.com/questions/38553927/batch-normalization-in-convolutional-neural-network
	3. https://arxiv.org/pdf/1502.03167.pdf
	4. https://www.quora.com/In-layman%E2%80%99s-terms-what-is-batch-normalisation-what-does-it-do-and-why-does-it-work-so-well

************ t-SNE  ************
	1. http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf
	2. https://mlexplained.com/2018/09/14/paper-dissected-visualizing-data-using-t-sne-explained/
	3. https://medium.com/@layog/i-dont-understand-t-sne-part-1-50f507acd4f9
	4. https://distill.pub/2016/misread-tsne/?source=post_page---------------------------

**********  GMM and EM algorithm  *************
	1. https://www.youtube.com/watch?v=REypj2sy_5U
	2. https://www.youtube.com/watch?v=iQoXFmbXRJA
	3. https://www.youtube.com/watch?v=QQJHsKfNqG8  

***********  Neural network and back prop  ********
	1. http://neuralnetworksanddeeplearning.com/chap2.html
	2. https://towardsdatascience.com/how-does-back-propagation-in-artificial-neural-networks-work-
	3. https://www.jeremyjordan.me/nn-learning-rate/

********* Tree based algorithms  *************
	1. https://medium.com/@rishabhjain_22692/decision-trees-it-begins-here-93ff54ef134
	2. https://stats.stackexchange.com/questions/353462/what-are-the-implications-of-scaling-the-features-to-xgboost/353464#353464

*************  Linear Algebra  ************
	1. https://www.ics.uci.edu/~welling/teaching/KernelsICS273B/MatrixCookBook.pdf
	2. https://www.comp.nus.edu.sg/~cs5240/lecture/matrix-differentiation.pdf

************ Unet for semantic segmentation  ************
	0. https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47
	1. https://medium.com/@keremturgutlu/semantic-segmentation-u-net-part-1-d8d6f6005066
	2. https://medium.com/activating-robotic-minds/up-sampling-with-transposed-convolution-9ae4f2df52d0
	3. https://www.jeremyjordan.me/semantic-segmentation/
	4. https://towardsdatascience.com/u-net-b229b32b4a71
	5. https://tuatini.me/practical-image-segmentation-with-unet/

********* Language Modeling and BPTT   **************
	1. http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/
	2. https://youtu.be/H3g26EVADgY?t=378

********  SVM  **************
	1. https://med.nyu.edu/chibi/sites/default/files/chibi/Final.pdf

**********  Object Detection  ************
	1. https://tryolabs.com/blog/2018/01/18/faster-r-cnn-down-the-rabbit-hole-of-modern-object-detection/
	2. http://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/
	3. https://medium.com/@smallfishbigsea/faster-r-cnn-explained-864d4fb7e3f8
	4. https://hackernoon.com/understanding-yolo-f5a74bbc7967
	5. https://medium.com/oracledevs/final-layers-and-loss-functions-of-single-stage-detectors-part-1-4abbfa9aa71c
	6. https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/
	7. https://medium.com/@jonathan_hui/real-time-object-detection-with-yolo-yolov2-28b1b93e2088

***********  Extras  ****************
	1. https://www.youtube.com/watch?v=h5Tz7gZT9Fo&feature=youtu.be&t=1h52m44s - BPT3C for LM fine tuning for classification
	2. https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/76883  -- Spatial Dropout






	


